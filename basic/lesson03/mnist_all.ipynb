{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. å¯¼å…¥æ•°æ®"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf # å¯¼å…¥ TF åº“\n",
    "from tensorflow import keras # å¯¼å…¥ TF å­åº“ keras\n",
    "from tensorflow.keras import layers, optimizers, datasets # å¯¼å…¥ TF å­åº“ç­‰"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data() # åŠ è½½ MNIST æ•°æ®é›†\n",
    "x = 2 * tf.convert_to_tensor(x, dtype=tf.float32)/255.-1 # è½¬æ¢ä¸ºæµ®ç‚¹å¼ é‡ï¼Œå¹¶ç¼©æ”¾åˆ°-1~1\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32) # è½¬æ¢ä¸ºæ•´å½¢å¼ é‡\n",
    "# y = tf.one_hot(y, depth=10) # one-hot ç¼–ç \n",
    "print(x.shape, y.shape)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y)) # æ„å»ºæ•°æ®é›†å¯¹è±¡\n",
    "train_dataset = train_dataset.batch(512) # æ‰¹é‡è®­ç»ƒ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. ç½‘ç»œæ­å»º\n",
    "å¯¹äºç¬¬ä¸€å±‚æ¨¡å‹æ¥è¯´ï¼Œå®ƒæ¥å—çš„è¾“å…¥ğ’™ âˆˆ ğ‘…784ï¼Œè¾“å‡ºğ’‰1 âˆˆ ğ‘…256è®¾è®¡ä¸ºé•¿åº¦ä¸º 256 çš„å‘\n",
    "é‡ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ˜¾å¼åœ°ç¼–å†™ğ’‰1 = ReLU(ğ‘¾1ğ’™ + ğ’ƒ1)çš„è®¡ç®—é€»è¾‘ï¼Œåœ¨ TensorFlow ä¸­é€šè¿‡ä¸€è¡Œä»£ç å³å¯å®ç°"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.layers.core.Dense at 0x18164103100>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "# åˆ›å»ºä¸€å±‚ç½‘ç»œï¼Œè®¾ç½®è¾“å‡ºèŠ‚ç‚¹æ•°ä¸º 256ï¼Œæ¿€æ´»å‡½æ•°ç±»å‹ä¸º ReLU\n",
    "layers.Dense(256, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "ä½¿ç”¨ TensorFlow çš„ Sequential å®¹å™¨å¯ä»¥éå¸¸æ–¹ä¾¿åœ°æ­å»ºå¤šå±‚çš„ç½‘ç»œã€‚å¯¹äº 3 å±‚ç½‘ç»œï¼Œæˆ‘ä»¬\n",
    "å¯ä»¥é€šè¿‡å¿«é€Ÿå®Œæˆ 3 å±‚ç½‘ç»œçš„æ­å»ºã€‚"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# åˆ©ç”¨ Sequential å®¹å™¨å°è£… 3 ä¸ªç½‘ç»œå±‚ï¼Œå‰ç½‘ç»œå±‚çš„è¾“å‡ºé»˜è®¤ä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥\n",
    "model = keras.Sequential([ # 3 ä¸ªéçº¿æ€§å±‚çš„åµŒå¥—æ¨¡å‹\n",
    " layers.Dense(256, activation='relu'), # éšè—å±‚ 1\n",
    " layers.Dense(128, activation='relu'), # éšè—å±‚ 2\n",
    " layers.Dense(10)]) # è¾“å‡ºå±‚ï¼Œè¾“å‡ºèŠ‚ç‚¹æ•°ä¸º 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ç¬¬ 1 å±‚çš„è¾“å‡ºèŠ‚ç‚¹æ•°è®¾è®¡ä¸º 256ï¼Œç¬¬ 2 å±‚è®¾è®¡ä¸º 128ï¼Œè¾“å‡ºå±‚èŠ‚ç‚¹æ•°è®¾è®¡ä¸º 10ã€‚ç›´æ¥è°ƒç”¨\n",
    "è¿™ä¸ªæ¨¡å‹å¯¹è±¡ model(x)å°±å¯ä»¥è¿”å›æ¨¡å‹æœ€åä¸€å±‚çš„è¾“å‡ºğ‘œã€‚"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.æ¨¡å‹è®­ç»ƒ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "æ­å»ºå®Œæˆ 3 å±‚ç¥ç»ç½‘ç»œçš„å¯¹è±¡åï¼Œç»™å®šè¾“å…¥ğ’™ï¼Œè°ƒç”¨ model(ğ’™)å¾—åˆ°æ¨¡å‹è¾“å‡ºğ‘œåï¼Œé€šè¿‡MSE æŸå¤±å‡½æ•°è®¡ç®—å½“å‰çš„è¯¯å·®â„’ï¼š"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD(learning_rate=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=2>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape: # æ„å»ºæ¢¯åº¦è®°å½•ç¯å¢ƒ\n",
    "    # æ‰“å¹³æ“ä½œï¼Œ[b, 28, 28] => [b, 784]\n",
    "    x = tf.reshape(x, (-1, 28*28))\n",
    "    # Step1. å¾—åˆ°æ¨¡å‹è¾“å‡º output [b, 784] => [b, 10]\n",
    "    out = model(x)\n",
    "    # [b] => [b, 10]\n",
    "    y_onehot = tf.one_hot(y, depth=10)\n",
    "    # è®¡ç®—å·®çš„å¹³æ–¹å’Œï¼Œ[b, 10]\n",
    "    loss = tf.square(out-y_onehot)\n",
    "    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„å¹³å‡è¯¯å·®ï¼Œ[b]\n",
    "    loss = tf.reduce_sum(loss) / x.shape[0]\n",
    "# Step3. è®¡ç®—å‚æ•°çš„æ¢¯åº¦ w1, w2, w3, b1, b2, b3\n",
    "grads = tape.gradient(loss, model.trainable_variables)\n",
    "# w' = w - lr * gradï¼Œæ›´æ–°ç½‘ç»œå‚æ•°\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "å†åˆ©ç”¨ TensorFlow æä¾›çš„è‡ªåŠ¨æ±‚å¯¼å‡½æ•° tape.gradient(loss, model.trainable_variables)æ±‚å‡ºæ¨¡\n",
    "å‹ä¸­æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ä¿¡æ¯ğœ•â„’/ğœ•ğœƒ , ğœƒ âˆˆ {ğ‘¾1, ğ’ƒ1,ğ‘¾2, ğ’ƒ2,ğ‘¾3, ğ’ƒ3}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
