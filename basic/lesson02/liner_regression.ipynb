{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![这是图片](./img.png)\n",
    "\n",
    "# 1.采样数据"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1495f4aeac03a148"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2ef9f30392419e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []# 保存样本集的列表\n",
    "for i in range(100): # 循环采样 100 个点\n",
    "    x = np.random.uniform(-10., 10.) # 随机采样输入 x\n",
    "    # 采样高斯噪声\n",
    "    eps = np.random.normal(0., 0.01)\n",
    "    # 得到模型的输出\n",
    "    y = 1.477 * x + 0.089 + eps\n",
    "    data.append([x, y]) # 保存样本点\n",
    "data = np.array(data) # 转换为 2D Numpy 数组"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 计算误差"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2da43c27e0b0bb2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mse(b, w, points):\n",
    "    # 根据当前的 w,b 参数计算均方差损失\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)): # 循环迭代所有点\n",
    "        x = points[i, 0] # 获得 i 号点的输入 x\n",
    "        y = points[i, 1] # 获得 i 号点的输出 y\n",
    "        # 计算差的平方，并累加\n",
    "        totalError += (y - (w * x + b)) ** 2\n",
    "    # 将累加的误差求平均，得到均方差\n",
    "    return totalError / float(len(points))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43a907682f035f21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 计算梯度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f11b55089720b6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def step_gradient(b_current, w_current, points, lr):\n",
    "    # 计算误差函数在所有点上的导数，并更新 w,b\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    M = float(len(points)) # 总样本数\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # 误差函数对 b 的导数：grad_b = 2(wx+b-y)，\n",
    "        b_gradient += (2/M) * ((w_current * x + b_current) - y)\n",
    "        # 误差函数对 w 的导数：grad_w = 2(wx+b-y)*x\n",
    "        w_gradient += (2/M) * x * ((w_current * x + b_current) - y)\n",
    "    # 根据梯度下降算法更新 w',b',其中 lr 为学习率\n",
    "    new_b = b_current - (lr * b_gradient)\n",
    "    new_w = w_current - (lr * w_gradient)\n",
    "    return [new_b, new_w]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbb49f832836ae94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 梯度更新\n",
    "在计算出误差函数在𝑤和𝑏处的梯度后，我们可以根据梯度式子来更新𝑤和𝑏的值。我们把\n",
    "对数据集的所有样本训练一次称为一个 Epoch，共循环迭代 num_iterations 个 Epoch。实现\n",
    "如下："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ec107e8a642282b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient_descent(points, starting_b, starting_w, lr, num_iterations):\n",
    "    # 循环更新 w,b 多次\n",
    "    b = starting_b # b 的初始值\n",
    "    w = starting_w # w 的初始值\n",
    "    # 根据梯度下降算法更新多次\n",
    "    for step in range(num_iterations):\n",
    "        # 计算梯度并更新一次\n",
    "        b, w = step_gradient(b, w, np.array(points), lr)\n",
    "        loss = mse(b, w, points) # 计算当前的均方差，用于监控训练进度\n",
    "        if step%50 == 0: # 打印误差和实时的 w,b 值\n",
    "            print(f\"iteration:{step}, loss:{loss}, w:{w}, b:{b}\")\n",
    "    return [b, w] # 返回最后一次的 w,b    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bd4736227aff976"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 加载训练集数据，这些数据是通过真实模型添加观测误差采样得到的\n",
    "    lr = 0.01 # 学习率\n",
    "    initial_b = 0 # 初始化 b 为 0\n",
    "    initial_w = 0 # 初始化 w 为 0\n",
    "    num_iterations = 1000\n",
    "    # 训练优化 1000 次，返回最优 w*,b*和训练 Loss 的下降过程\n",
    "    [b, w]= gradient_descent(data, initial_b, initial_w, lr, num_iterations)\n",
    "    loss = mse(b, w, data) # 计算最优数值解 w,b 上的均方差\n",
    "    print(f'Final loss:{loss}, w:{w}, b:{b}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1772dbebeb3a66a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
