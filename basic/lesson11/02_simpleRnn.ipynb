{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "通过 SimpleRNNCell 层的使用，我们可以非常深入地理解循环神经网络前向运算的每\n",
    "个细节，但是在实际使用中，为了简便，不希望手动参与循环神经网络内部的计算过程，\n",
    "比如每一层的 状态向量的初始化，以及每一层在时间轴上展开的运算。通过 SimpleRNN\n",
    "层高层接口可以非常方便地帮助我们实现此目的。\n",
    "比如我们要完成单层循环神经网络的前向运算，可以方便地实现如下："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2cfa982d192f852"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5df36546fd934f6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = layers.SimpleRNN(64) # 创建状态向量长度为 64 的 SimpleRNN 层\n",
    "x = tf.random.normal([4, 80, 100])\n",
    "out = layer(x) # 和普通卷积网络一样，一行代码即可获得输出\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，通过 SimpleRNN 可以仅需一行代码即可完成整个前向运算过程，它默认返回最\n",
    "后一个时间戳上的输出。\n",
    "如果希望返回所有时间戳上的输出列表，可以设置 return_sequences=True 参数，代码\n",
    "如下："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "267e3189c5c3d4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建 RNN 层时，设置返回所有时间戳上的输出\n",
    "layer = layers.SimpleRNN(64,return_sequences=True)\n",
    "out = layer(x) # 前向计算\n",
    "out # 输出，自动进行了 concat 操作"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19c8f96beca78221"
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，返回的输出张量 shape 为[4,80,64]，中间维度的 80 即为时间戳维度。同样的，\n",
    "对于多层循环神经网络，我们可以通过堆叠多个 SimpleRNN 实现，如两层的网络，用法和\n",
    "普通的网络类似"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a73b4fd0181220a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = keras.Sequential([ # 构建 2 层 RNN 网络\n",
    "# 除最末层外，都需要返回所有时间戳的输出，用作下一层的输入\n",
    "layers.SimpleRNN(64, return_sequences=True),\n",
    "layers.SimpleRNN(64),\n",
    "])\n",
    "out = net(x) # 前向计算"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58ea93f63f681bd9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "每层都需要上一层在每个时间戳上面的状态输出，因此除了最末层以外，所有的 RNN 层\n",
    "都需要返回每个时间戳上面的状态输出，通过设置 return_sequences=True 来实现。可以看\n",
    "到，使用 SimpleRNN 层，与卷积神经网络的用法类似，非常简洁和高效。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d46d84393da5ed8"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ec1d05dc3b2b79ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
